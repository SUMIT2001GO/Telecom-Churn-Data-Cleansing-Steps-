{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d557014b-f550-45d0-85d6-ab69027495a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "835e6952-bb4d-4837-a27e-8cc9f0aae12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df = pd.read_csv(r\"C:\\Users\\SUMIT MITRA\\Churn_ Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2949b6c7-b617-4d5d-998c-f726427f6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9223f90e-18ff-41ff-a561-f95bf0a5e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "df.drop_duplicates(keep = 'first' , inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b482d33-6ead-4a24-a285-fba109dfc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print(df.apply(lambda col: col.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cb5ac37-5b19-4d52-9c8a-02ddb8278fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "unique_counts = df.nunique()\n",
    "# Filter out columns with only one unique value\n",
    "df_filtered = df.loc[:, unique_counts > 1]\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "406f4a43-5153-42fe-b4ae-c8b9a1baca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "threshold = len(df) * 0.8\n",
    "# Iterate over each column\n",
    "for col in df.columns:\n",
    "    # Check if the number of unique values exceeds the threshold\n",
    "    if df[col].nunique() >= threshold:\n",
    "        # If the number of unique values exceeds the threshold, drop the column\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38dc3da2-a5fb-4ed8-9e0a-db466e0b3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "threshold = 0.9\n",
    "variances = df.var()\n",
    "non_zero_variance_columns = variances[variances != 0]\n",
    "# Create a new DataFrame with the filtered columns\n",
    "df_filtered = df[non_zero_variance_columns.index]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32a8f5f4-5d24-4742-b063-c5f6d357f27c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64'])\n",
    "# Calculate skewness for each numerical column\n",
    "skewness = numerical_columns.apply(lambda x: x.skew())\n",
    "# Threshold to identify skewed columns\n",
    "threshold = 0.8\n",
    "# Filter columns with skewness above the threshold\n",
    "skewed_columns = skewness[abs(skewness) >= threshold]\n",
    "print(skewed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "276fcf50-840e-4464-aa70-7308cca0ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot for {col}')\n",
    "    plt.show()\n",
    "    # Determine the IQR\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # Define thresholds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Filter out outliers\n",
    "    df_filtered = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e1b7d70-1c19-432d-94ce-2f748d1a7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "columns_to_standardize = []\n",
    "for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    mean = df[column].mean()\n",
    "    std_dev = df[column].std()\n",
    "    df[column] = (df[column] - mean) / std_dev\n",
    "    # Check if there are any outliers using +- 3 sigma approach\n",
    "    if ((df[column] >= -3) & (df[column] <= 3)).all():\n",
    "        columns_to_standardize.append(column)\n",
    "# Now, the suitable columns have been standardized using +- 3 sigma approach\n",
    "print(\"Columns suitable for standardization:\")\n",
    "print(columns_to_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89deaf2d-3306-426a-a7b6-5e5206f5086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    lower_percentile = df[col].quantile(0.01)\n",
    "    upper_percentile = df[col].quantile(0.99)\n",
    "    # Display the capped and floored column stats\n",
    "    print(f'\\nCapped and Floored {col}:')\n",
    "    print(df[col].describe())\n",
    "    print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16cae507-07e5-4169-8610-7a500b7c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "corr_matrix = df.corr().abs()\n",
    "# Select the upper triangle of the correlation matrix\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "# Find columns with a correlation greater than 0.90\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.90)]\n",
    "df_reduced = df.drop(columns=to_drop)\n",
    "print(f'Dropped columns: {to_drop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "353f6abb-ff03-4921-8437-bc7049e33af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "print({df_reduced.shape[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b433cc9-8a3d-40c0-8f84-d75ff3bfe9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def calculate_vif(dataframe):\n",
    "    # The DataFrame will be modified in-place\n",
    "    variables = list(dataframe.columns)\n",
    "    vif = {}\n",
    "    for var in variables:\n",
    "        vif[var] = variance_inflation_factor(dataframe.values, variables.index(var))\n",
    "    return vif\n",
    "# Calculate VIF for all columns\n",
    "vif_data = calculate_vif(df)\n",
    "for column, value in vif_data.items():\n",
    "    if value > 5:\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "# Now df has reduced multicollinearity\n",
    "print(f'Remaining columns: {df.columns.tolist()}')\n",
    "print(f'Number of columns: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c38b6-0fc7-4457-a4bc-08d3e4201dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
